{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "import config\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "\n",
    "import requests\n",
    "import pydotplus\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import plot_tree\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import tree, metrics, svm, datasets\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, label_binarize\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, average_precision_score, precision_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Relevant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.whatbird.com/browse/attributes.aspx')\n",
    "location_table = driver.find_element_by_class_name('BrowseTable')\n",
    "links = location_table.find_elements_by_css_selector(\"a\")\n",
    "\n",
    "bird_families = [] \n",
    "bird_chars = []\n",
    "for i in tqdm(range(1, len(links))):\n",
    "    locale = driver.find_element_by_class_name('BrowseTable').find_elements_by_css_selector(\"a\")[i]\n",
    "    locale.click()\n",
    "    landing_page = driver.current_url\n",
    "    for ind in tqdm(range(len(driver.find_elements_by_xpath(\"//*[contains(@class,'ObjectLink')]\")))):\n",
    "        location_page = driver.current_url\n",
    "        driver.find_elements_by_xpath(\"//*[contains(@class,'ObjectLink')]\")[ind].click()\n",
    "        driver.find_element_by_link_text('Identification').click()\n",
    "        bird_chars_table = driver.find_element_by_class_name('contentbg')\n",
    "        char_list = bird_chars_table.find_elements_by_css_selector('li')\n",
    "        bird_text = [driver.find_element_by_id('BirdName').text]\n",
    "        for i in char_list:\n",
    "            bird_text.append(i.text)\n",
    "\n",
    "        bird_chars.append(bird_text)\n",
    "        bird_families.append(driver.find_element_by_id(\"Family\").text)\n",
    "        driver.get(location_page)\n",
    "\n",
    "    driver.get('https://www.whatbird.com/browse/attributes.aspx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Scraped Data and Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = []\n",
    "for elem in bird_chars:\n",
    "    if elem not in birds:\n",
    "        birds.append(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to MySQL/Creating a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'Bird_Classifier_Project'\n",
    "cnx = mysql.connector.connect(\n",
    "    host = config.host,\n",
    "    user = config.user,\n",
    "    passwd = config.pw\n",
    "\n",
    ")\n",
    "cur = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(cursor, database):\n",
    "    try:\n",
    "        cur.execute(\n",
    "            \"CREATE DATABASE {} DEFAULT CHARACTER SET 'utf8'\".format(database))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Failed creating database: {}\".format(err))\n",
    "        exit(1)\n",
    "\n",
    "try:\n",
    "    cur.execute(\"USE {}\".format(db_name))\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"Database {} does not exists.\".format(db_name))\n",
    "    if err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        create_database(cur, db_name)\n",
    "        print(\"Database {} created successfully.\".format(db_name))\n",
    "        cnx.database = db_name\n",
    "    else:\n",
    "        print(err)\n",
    "        exit(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "CREATE TABLE birds (\n",
    "Family VARCHAR(255),\n",
    "Name VARCHAR(255),\n",
    "Bill_Shape VARCHAR(255),\n",
    "Eye_Color VARCHAR(255),\n",
    "Head_Pattern VARCHAR(255),\n",
    "Crown_Color VARCHAR(255),\n",
    "Forehead_Color VARCHAR(255),\n",
    "Nape_Color VARCHAR(255),\n",
    "Throat_Color VARCHAR(255),\n",
    "Cere_Color VARCHAR(255),\n",
    "Length_Range VARCHAR(255),\n",
    "Weight VARCHAR(255),\n",
    "Size VARCHAR(255),\n",
    "Primary_Color VARCHAR(255),\n",
    "Underparts VARCHAR(255),\n",
    "Upperparts VARCHAR(255),\n",
    "Back_Pattern VARCHAR(255),\n",
    "Belly_Pattern VARCHAR(255),\n",
    "Breast_Pattern VARCHAR(255),\n",
    "Flight_Pattern VARCHAR(255),\n",
    "Wingspan VARCHAR(255),\n",
    "Wing_Shape VARCHAR(255),\n",
    "Tail_Shape VARCHAR(255),\n",
    "Tail_Pattern VARCHAR(255),\n",
    "Upper_Tail VARCHAR(255),\n",
    "Under_Tail VARCHAR(255),\n",
    "Leg_Color VARCHAR(255)\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_list = []\n",
    "for i in range(len(bird_chars)):\n",
    "    cleaner_list.append(tuple((bird_chars[1][0][0],bird_chars[i][1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_lists = []\n",
    "for i in range(len(cleaner_list)):\n",
    "    nested_lists.append([clieaner_list[i][0]]+cleaner_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_birds = list(nested_lists for nested_lists,_ in itertools.groupby(nested_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unique_birds:\n",
    "    del i[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(unique_birds)\n",
    "df['Family'] = bird_families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bird_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"0\", \n",
    "                     keep = 'first', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.astype(str)\n",
    "subset = df[['Family','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19', '20', '21', '22', '23', '24', '25']]\n",
    "tuples = [tuple(x) for x in subset.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(\n",
    "    host = config.host,\n",
    "    user = config.user,\n",
    "    passwd = config.pw,\n",
    "    database = db_name\n",
    ")\n",
    "cur = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(tuples):\n",
    "    try:\n",
    "        stmt = \"\"\"INSERT INTO birds (Family, Name, Bill_Shape, Eye_Color, Head_Pattern, Crown_Color, Forehead_Color,\n",
    "        Nape_Color, Throat_Color, Cere_Color, Length_Range, Weight, Size, Primary_Color, Underparts, Upperparts, \n",
    "        Back_Pattern, Belly_Pattern, Breast_Pattern, Flight_Pattern, Wingspan, Wing_Shape, Tail_Shape, Tail_Pattern,\n",
    "        Upper_Tail, Under_Tail, Leg_Color) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "        \n",
    "        \"\"\"\n",
    "        cur.execute(stmt, (i))\n",
    "        cnx.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"SELECT * FROM birds\"\"\")\n",
    "df1 = pd.DataFrame(cur.fetchall())\n",
    "df1.columns = [x[0] for x in cur.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fams = list(df1.Family)\n",
    "\n",
    "new_fams = []\n",
    "for i in fams:\n",
    "    new_fams.append(i.split(\"(\"))\n",
    "\n",
    "real_fams = []\n",
    "for i in new_fams:\n",
    "    real_fams.append(i[1].split(\")\")[0])\n",
    "\n",
    "df1['Family'] = real_fams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Eye_Color = df1.Eye_Color.str[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.Bill_Shape.str.contains(\"Eye Color\")]\n",
    "df1 = df1[~df1.Eye_Color.str.contains(\"Eye Color\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing redundant column label in each row ###\n",
    "\n",
    "df1.Bill_Shape = df1.Bill_Shape.str[12:]\n",
    "df1.Eye_Color = df1.Eye_Color.str[11:]\n",
    "df1.Head_Pattern = df1.Head_Pattern.str[14:]\n",
    "df1.Crown_Color = df1.Crown_Color.str[13:]\n",
    "df1.Forehead_Color = df1.Forehead_Color.str[16:]\n",
    "df1.Nape_Color = df1.Nape_Color.str[12:]\n",
    "df1.Throat_Color = df1.Throat_Color.str[14:]\n",
    "df1.Cere_Color = df1.Cere_Color.str[12:]\n",
    "df1.Length_Range = df1.Length_Range.str[14:]\n",
    "df1.Weight = df1.Weight.str[8:]\n",
    "df1.Size = df1.Size.str[5:]\n",
    "df1.Primary_Color = df1.Primary_Color.str[15:]\n",
    "df1.Underparts = df1.Underparts.str[12:]\n",
    "df1.Upperparts = df1.Upperparts.str[12:]\n",
    "df1.Back_Pattern = df1.Back_Pattern.str[14:]\n",
    "df1.Belly_Pattern = df1.Belly_Pattern.str[15:]\n",
    "df1.Breast_Pattern = df1.Breast_Pattern.str[16:]\n",
    "df1.Flight_Pattern = df1.Flight_Pattern.str[16:]\n",
    "df1.Wingspan = df1.Wingspan.str[10:]\n",
    "df1.Wing_Shape = df1.Wing_Shape.str[11:]\n",
    "df1.Tail_Shape = df1.Tail_Shape.str[12:]\n",
    "df1.Tail_Pattern = df1.Tail_Pattern.str[14:]\n",
    "df1.Upper_Tail = df1.Upper_Tail.str[12:]\n",
    "df1.Under_Tail = df1.Under_Tail.str[12:]\n",
    "df1.Leg_Color = df1.Leg_Color.str[11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(columns=['Eye_Color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Vanilla Classifier (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df1.drop(columns=['Family','Name','Size','Length_Range','Weight','Wingspan']))\n",
    "y = (df1['Family'])\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclass = DecisionTreeClassifier(criterion='entropy',random_state=10)\n",
    "dtclass.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = dtclass.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy \n",
    "acc = accuracy_score(y_test,y_preds)*100\n",
    "print(\"Accuracy score is {:.4}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Testing Score of 59.18%. Nice!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_true, y_predict):\n",
    "    \"\"\" \n",
    "    Calculates and returns the performance score between \n",
    "    true and predicted values based on the metric chosen.\n",
    "    \"\"\"    \n",
    "    r2 = (metrics.r2_score(y_true,y_predict))\n",
    "    mse = metrics.mean_squared_error(y_true,y_predict)\n",
    "    return r2,mse\n",
    "performance(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree = BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5,random_state=10),n_estimators=20,random_state=10)\n",
    "bagged_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bagged_tree.score(X_train,y_train))\n",
    "print(bagged_tree.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100,max_depth=5,random_state=10)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest.score(X_train,y_train))\n",
    "print(forest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt_cv_score = cross_val_score(dtclass,X,y,cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "print(\"Mean Cross Validation Score: {:.4}%\".format(mean_dt_cv_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearching Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16 ,18, 20, 22, 24, 26, 28, 30, 32, 34],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "dt_grid_search = GridSearchCV(dtclass,dt_param_grid,cv=3,return_train_score=True)\n",
    "\n",
    "dt_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gs_training_score = dt_grid_search.cv_results_['mean_train_score']\n",
    "dt_gs_testing_score = dt_grid_search.score(X,y)\n",
    "\n",
    "print(\"Mean Training Score: {:.4}%\".format(np.mean(dt_gs_training_score) * 100))\n",
    "print(\"Mean Testing Score: {:.4}%\".format(np.mean(dt_gs_testing_score) * 100))\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_class = RandomForestClassifier()\n",
    "dt_cv_score = cross_val_score(forest_class,X,y,cv=3)\n",
    "mean_rf_cv_score = np.mean(dt_cv_score)\n",
    "print(\"Mean Cross Validation Score for Random Forest Classifier: {:.4}%\".format(mean_rf_cv_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16 ,18, 20, 22, 24, 26, 28, 30, 32, 34],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5, 6],\n",
    "    \"n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_grid_search = GridSearchCV(forest_class,rf_param_grid,cv=3)\n",
    "rf_grid_search.fit(X, y)\n",
    "\n",
    "print(\"Testing Accuracy: {:.4}%\".format(rf_grid_search.best_score_ * 100))\n",
    "print(\"Total Runtime for Grid Search on Random Forest Classifier: {:.4} seconds\".format(time.time() - start))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(rf_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Up to 66.38%. Better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed Target to Size and Combined 5 categories into 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1['Size'] == ' Very Small (3 - 5 in)', 'Size'] = ' Small (5 - 9 in)'\n",
    "df1.loc[df1['Size'] == ' Very Large (32 - 72 in)'] = ' Large (16 - 32 in)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df1.drop(columns=['Family','Name','Size','Length_Range','Weight','Wingspan']))\n",
    "y = (df1['Size'])\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.4,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=10)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_score = cross_val_score(forest,X,y,cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "print(\"Mean Cross Validation Score: {:.4}%\".format(mean_dt_cv_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16 ,18, 20, 22, 24, 26, 28, 30, 32, 34],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(forest,forest_param_grid,cv=3,return_train_score=True)\n",
    "\n",
    "dt_grid_search.fit(X, y)\n",
    "\n",
    "dt_gs_training_score = dt_grid_search.cv_results_['mean_train_score']\n",
    "dt_gs_testing_score = dt_grid_search.score(X,y)\n",
    "\n",
    "print(\"Mean Training Score: {:.4}%\".format(np.mean(dt_gs_training_score) * 100))\n",
    "print(\"Mean Testing Score: {:.4}%\".format(np.mean(dt_gs_testing_score) * 100))\n",
    "print(\"Best Parameter Combination Found During Grid Search:\")\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=10, max_depth=34, min_samples_leaf=1, min_samples_split=5, criterion='gini')\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_score = cross_val_score(forest,X,y,cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "print(\"Mean Cross Validation Score: {:.4}%\".format(mean_dt_cv_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "classes = ['Small','Medium','Large']\n",
    "plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)\n",
    "print(precision_score(y_test, y_pred,average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time()\n",
    "svclassifier = SVC(kernel='rbf', C=1)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)\n",
    "toc = time()\n",
    "print(\"run time is {} seconds\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) \n",
    "print(\"The accuracy score is\" + \" \"+ str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_selection(X, y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-running SVC with Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tic = time()\n",
    "svclassifier = SVC(kernel='rbf', C=10, gamma=0.01)  \n",
    "svclassifier.fit(X_train, y_train) \n",
    "y_pred = svclassifier.predict(X_test)\n",
    "toc = time()\n",
    "print(\"run time is {} seconds\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) \n",
    "print(\"The accuracy score is\" + \" \"+ str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Synthetic Minority Over-sampling Technique (SMOTE) on Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SVC(kernel='rbf', C=10, gamma=0.01).fit(X_train,y_train)\n",
    "smote_pred = smote.predict(X_test)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, smote_pred))\n",
    "print(classification_report(y_test,smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('real_bird_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearched Neural Network Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df1.Flight_Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_words = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_words = pd.DataFrame(x_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_words.reset_index(drop=True, inplace=True)\n",
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_X = pd.concat([df1,x_words], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_X = bow_X.drop(columns=[0,1,9,10,11,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bow_with_features = pd.get_dummies(bow_X)\n",
    "y = df1['Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(bow_with_features,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=45)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_score = cross_val_score(forest,X,y,cv=3)\n",
    "mean_dt_cv_score = np.mean(dt_cv_score)\n",
    "print(\"Mean Cross Validation Score: {:.4}%\".format(mean_dt_cv_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16 ,18, 20, 22, 24, 26, 28, 30, 32, 34],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5, 6],\n",
    "    \"n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid_search = GridSearchCV(forest,rf_param_grid,cv=3,return_train_score=True)\n",
    "\n",
    "dt_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy: {:.4}%\".format(dt_grid_search.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(dt_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SMOTE ###\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random-searched SVC Using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_param_selection(bow_with_features, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SVC(kernel='rbf', C=10, gamma=0.01,random_state=10).fit(X_train,y_train)\n",
    "smote_pred = smote.predict(X_test)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, smote_pred))\n",
    "print(classification_report(y_test,smote_pred))\n",
    "print(\"The accuracy score is\" + \" \"+ str(accuracy_score(y_test, smote_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_randomizedsearchCV(X, y, nfolds):\n",
    "    degrees = [2,3,4,5]\n",
    "    kernels = ['rbf','poly']\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel': kernels, 'degree': degrees}\n",
    "    grid_search = RandomizedSearchCV(svm.SVC(), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_randomizedsearchCV(bow_with_features,y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SVC(kernel='rbf', C=1, gamma=0.01, degree=5,random_state=10).fit(X_train,y_train)\n",
    "smote_pred = smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, smote_pred,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, smote_pred))\n",
    "print(classification_report(y_test,smote_pred)) \n",
    "print(\"The accuracy score is\" + \" \"+ str(accuracy_score(y_test, smote_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BEST MODEL  ^^^^^**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting Better Score Using Principle Component Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow_with_features\n",
    "y = (df1['Size'])\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "transformed = pca.fit_transform(X)\n",
    "\n",
    "# Your code here \n",
    "\n",
    "first_two_comp = (transformed[:,0], transformed[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(transformed[:,0], transformed[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_value, eigen_vector = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_indices = np.argsort(eigen_value)[::-1] #Get the index values of the sorted eigenvalues\n",
    "eigenvectors_sorted = eigen_vector[:,e_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = eigenvectors_sorted.dot(transformed).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs=pd.DataFrame(first_two_comp).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance of each component:', pca.explained_variance_ratio_)\n",
    "print('\\n Total Variance Explained:', round(sum(list(pca.explained_variance_ratio_))*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pcs\n",
    "y = (df1['Size'])\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
    "model = SVC(kernel='rbf', C=10, gamma=0.001, degree=4).fit(X_train,y_train)\n",
    "model.fit(X_train, Y_train)\n",
    "Yhat = model.predict(X_test)\n",
    "acc = metrics.accuracy_score(Yhat, Y_test)\n",
    "end = time.time()\n",
    "print(\"Accuracy:\",acc)\n",
    "print (\"Time Taken:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After playing around with the different eigenvalues, accuracy using PCA isn't as good as our SVC model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Classification Evaluation! // BEST MODEL: SMOTE SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival Count\n",
    "print('Target Variable')\n",
    "print(df1.groupby(['Size']).Size.count())\n",
    "\n",
    "# Target Variable Countplot\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(df1['Size'], alpha =.80, palette= ['yellowgreen','lightgreen','darkgreen'])\n",
    "plt.title('Bird Sizes')\n",
    "plt.ylabel('# of Birds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,smote_pred)\n",
    "classes = ['Small','Medium','Large']\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)\n",
    "print(precision_score(y_test, smote_pred,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', smote_pred[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_test, smote_pred, average=None))\n",
    "print(metrics.recall_score(y_test, smote_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the F1 score\n",
    "2*(metrics.precision_score(y_test, smote_pred,average=None)*metrics.recall_score(y_test, smote_pred,average=None))/(metrics.precision_score(y_test, smote_pred,average=None)+metrics.recall_score(y_test, smote_pred,average=None))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "THRESHOLD = 0.5\n",
    "preds = np.where(logreg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "pd.DataFrame(data=[np.mean(metrics.recall_score(y_test, smote_pred,average=None)),\n",
    "                   np.mean(metrics.precision_score(y_test, smote_pred,average=None)), np.mean(metrics.f1_score(y_test, smote_pred,average=None))], \n",
    "             index=[\"recall\", \"precision\", \"F1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_test)[:, 2]\n",
    "plt.hist(y_pred_prob, bins=8)\n",
    "plt.xlim(0, 1)\n",
    "plt.title('Histogram of Predicted Probabilities')\n",
    "plt.xlabel('Predicted Probability of Bird Being Medium')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "adaboost_mean_cv_score = np.mean(cross_val_score(adaboost_clf, X, y, cv=3))\n",
    "print(\"Mean Cross Validation Score for AdaBoost: {:.4}%\".format(adaboost_mean_cv_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_param_grid = {\n",
    "    'n_estimators': [50,100,250, 500],\n",
    "    'learning_rate': [1.0, 0.5, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_grid_search = GridSearchCV(adaboost_clf, adaboost_param_grid, cv=3)\n",
    "adaboost_grid_search.fit(X, y)\n",
    "print(\"Testing Accuracy: {:.4}%\".format(adaboost_grid_search.best_score_ * 100))\n",
    "print(\"Total Runtime for Grid Search on AdaBoost: {:.4} seconds\".format(time.time() - start))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(adaboost_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf = GradientBoostingClassifier()\n",
    "gbt_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf_train_preds = gbt_clf.predict(X_train)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds, average='weighted')\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "print(gbt_confusion_matrix)\n",
    "gbt_classification_report = classification_report(y_test, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean GBT Cross-Val Score (k=5):')\n",
    "print(cross_val_score(gbt_clf, X, y, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bow_with_features\n",
    "y = (df1['Size'])\n",
    "X.columns = X.columns.astype(str)\n",
    "X.columns = X.columns.str.replace(' ', '_')\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"learning_rate\": [0.1],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [10],\n",
    "    'subsample': [ 0.7],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfX=XGBClassifier()\n",
    "clfX.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_clf = GridSearchCV(clfX, xgb_param_grid, scoring='accuracy', cv=5, n_jobs=1)\n",
    "grid_clf.fit(bow_with_features, y)\n",
    "best_parameters = grid_clf.best_params_\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "training_preds = grid_clf.predict(X_train)\n",
    "val_preds = grid_clf.predict(X_test)\n",
    "training_accuracy = accuracy_score(y_train, training_preds)\n",
    "val_accuracy = accuracy_score(y_test, val_preds)\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "print(\"Testing Accuracy(Best Score): {:.4}%\".format(grid_clf.best_score_ * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(13,10))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(clfX,max_num_features=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(clfX, num_trees=1)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(100, 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
